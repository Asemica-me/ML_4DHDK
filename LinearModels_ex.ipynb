{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises from 2_Linear_Classification Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for evrth\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A) Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "1. Develop the Softmax classifier using a dataset of your choice. See [this module](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) from PyTorch.\n",
    "2. Develop a model to solve this regression task (below). Consider adding at least two layers and a non-linearity to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Develop the Softmax classifier using a dataset of your choice.\n",
    "\n",
    "It will be used the Iris dataset, more suitable for a multi-class classification tasks, where the output is a probability distribution over multiple classes.\n",
    "\n",
    "### Steps:\n",
    "* Load and preprocess the dataset (Iris dataset).\n",
    "* Define the Softmax classifier using PyTorch.\n",
    "* Train the classifier using the training data.\n",
    "* Evaluate the model on a test set.\n",
    "* Visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn # neural network, it's a sub-library of pytorch which contains many different components for neural network\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The Iris dataset has 4 features and 3 classes. The dataset is split into training and test sets.\n",
    "\n",
    "The features are normalized using `StandardScaler` to improve training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris['data']  # Features\n",
    "y = iris['target']  # Labels (0, 1, 2)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# Step 2: Create a PyTorch Dataset and DataLoader for batching\n",
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_data = IrisDataset(X_train, y_train)\n",
    "test_data = IrisDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "A simple linear layer maps the input features to the number of classes. The `CrossEntropyLoss` function applies Softmax internally, so we don't need to explicitly apply Softmax in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the Softmax Classifier model\n",
    "class SoftmaxClassifier(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(SoftmaxClassifier, self).__init__()\n",
    "        # A linear layer with output size equal to the number of classes\n",
    "        self.linear = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        return logits  # Softmax is applied inside CrossEntropyLoss\n",
    "\n",
    "# Initialize the model\n",
    "num_features = X_train.shape[1]  # Number of input features (4 for the Iris dataset)\n",
    "num_classes = len(np.unique(y))  # Number of classes (3 for the Iris dataset)\n",
    "\n",
    "model = SoftmaxClassifier(num_features, num_classes)\n",
    "\n",
    "# Step 4: Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Combines LogSoftmax and NLLLoss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "The model is trained for 100 epochs, and the loss is printed every 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train the model\n",
    "def train_model(model, train_loader, optimizer, criterion, num_epochs=100):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "The model's accuracy is evaluated on the test set, with the accuracy printed after evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "The dataset is reduced to 2 dimensions and plot the decision boundary to visualize how the Softmax classifier divides the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Visualize decision boundaries (2D projection)\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    model.eval()\n",
    "    \n",
    "    # Project the data onto a 2D plane (for visualization)\n",
    "    X = X[:, :2].cpu().numpy()\n",
    "    y = y.cpu().numpy()\n",
    "\n",
    "    # Generate a grid of points\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "    # Make predictions over the grid\n",
    "    grid_points = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()]).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(grid_points)\n",
    "        _, Z = torch.max(logits, 1)\n",
    "    Z = Z.cpu().reshape(xx.shape)\n",
    "\n",
    "    # Plot decision boundary\n",
    "    plt.contourf(xx, yy, Z, alpha=0.5, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Spectral)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title('Decision Boundary for Softmax Classifier')\n",
    "    plt.show()\n",
    "\n",
    "# Reduce the dataset to 2 features for visualization purposes\n",
    "X_train_2D = X_train[:, :2]\n",
    "model_2D = SoftmaxClassifier(2, num_classes).to(device)\n",
    "train_model(model_2D, DataLoader(IrisDataset(X_train_2D, y_train), batch_size=16), optimizer, criterion)\n",
    "\n",
    "# Plot decision boundary\n",
    "plot_decision_boundary(model_2D, X_train_2D, y_train)\n",
    "\n",
    "# decision boundary plot for a Softmax classifier, applied to a 2D projection of the Iris dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot, the different regions represent the decision boundaries where the classifier predicts different classes. Each color corresponds to a different class, and the points represent the data samples, with colors denoting the true class labels.\n",
    "\n",
    "The classifier has learned to separate the feature space into three regions, with boundaries that aim to divide the data according to the class probabilities. From this visualization, it looks like the Softmax classifier has effectively captured the relationships between the two selected features and their respective classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Develop a model to solve this regression task below. \n",
    "Consider adding at least two layers and a non-linearity to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Consider the following dataset\n",
    "from sklearn.datasets import make_regression # a simpler way to create regression data\n",
    "x, y = make_regression(n_samples=1000, n_features=1, noise=0.2)\n",
    "y = np.power(y,2)\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the target variable 𝑦 has been squared (y = np.power(y, 2)), this adds non-linearity to the problem, the model will include non-linear activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/500], Loss: 107920.5078\n",
      "Epoch [100/500], Loss: 105010.6719\n",
      "Epoch [150/500], Loss: 98166.6172\n",
      "Epoch [200/500], Loss: 86385.5391\n",
      "Epoch [250/500], Loss: 70786.1094\n",
      "Epoch [300/500], Loss: 55017.8203\n",
      "Epoch [350/500], Loss: 43049.5273\n",
      "Epoch [400/500], Loss: 35256.7930\n",
      "Epoch [450/500], Loss: 29699.1230\n",
      "Epoch [500/500], Loss: 25330.3184\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Step 1: Create the dataset\n",
    "x, y = make_regression(n_samples=1000, n_features=1, noise=0.2)\n",
    "y = np.power(y, 2) # Square the target variable for non-linearity\n",
    "\n",
    "# Convert the dataset to PyTorch tensors\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).view(-1, 1) # Reshape y to be a 2D tensor\n",
    "\n",
    "# Step 2: Define the neural network model\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(1, 64)   # First layer: input to hidden\n",
    "        self.fc2 = nn.Linear(64, 32)  # Second layer: hidden to hidden\n",
    "        self.fc3 = nn.Linear(32, 1)   # Output layer\n",
    "        \n",
    "        # Non-linearity (ReLU) Activation Function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))  # First layer with ReLU activation\n",
    "        x = self.relu(self.fc2(x))  # Second layer with ReLU activation\n",
    "        x = self.fc3(x)             # Output layer (no activation function for regression)\n",
    "        return x\n",
    "\n",
    "# Step 3: Initialize the model, loss function, and optimizer\n",
    "model = RegressionModel()\n",
    "loss_function = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer for faster convergence\n",
    "\n",
    "# Step 4: Train the model\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    # Forward pass: compute the model output\n",
    "    preds = model(x)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = loss_function(preds, y)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()  # Zero out the gradients\n",
    "    loss.backward()        # Compute the gradients\n",
    "    optimizer.step()       # Update the model parameters\n",
    "    \n",
    "    # Print the loss every 50 epochs\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Step 5: Visualize the results\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    predictions = model(x).cpu().numpy()\n",
    "\n",
    "# Plot the original data and the predictions\n",
    "plt.plot(x.numpy(), y.numpy(), 'x', label='True data')\n",
    "plt.plot(x.numpy(), predictions, '.', label='Model predictions', color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture:\n",
    "\n",
    "The model consists of three fully connected layers (nn.Linear), where:\n",
    "\n",
    "The first layer takes in 1 input feature and outputs 64 hidden units.\n",
    "The second layer takes 64 hidden units and outputs 32 hidden units.\n",
    "The final layer outputs a single value for each sample (since it's a regression task).\n",
    "ReLU activation is applied after the first two layers to introduce non-linearity.\n",
    "\n",
    "Loss Function: Mean Squared Error (MSE) is used, which is standard for regression tasks.\n",
    "\n",
    "\n",
    "Optimizer:\n",
    "\n",
    "Adam optimizer is chosen for faster and more efficient convergence, as it adapts the learning rate during training.\n",
    "\n",
    "\n",
    "Training Process:\n",
    "\n",
    "The model is trained for 500 epochs. After every 50 epochs, the loss is printed to monitor the training progress.\n",
    "\n",
    "Visualization:\n",
    "\n",
    "After training, we plot the model’s predictions against the true data points to see how well the model has learned the relationship.\n",
    "\n",
    "Results:\n",
    "\n",
    "After training, the red dots (predicted values) should follow the general trend of the true data points, showing that the model has captured the underlying relationship in the dataset.\n",
    "\n",
    "This model introduces non-linearity through the ReLU activation function, allowing it to better fit the squared regression task compared to a simple linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (B) Linear Classification and MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "1. Change the architecture of the network (e.g., add more layers, change the non-linearity, the number of parameters, etc.): Can you get better results?\n",
    "2. Change the training procedure (e.g., more or less epochs, smaller or larger batches of data, etc.): Can you get better results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UpdatedMLPClassifier(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch 1/20, loss: 2.292838  [   32/60000]\n",
      "Epoch 1/20, loss: 0.431771  [ 6432/60000]\n",
      "Epoch 1/20, loss: 0.568895  [12832/60000]\n",
      "Epoch 1/20, loss: 0.378868  [19232/60000]\n",
      "Epoch 1/20, loss: 0.573394  [25632/60000]\n",
      "Epoch 1/20, loss: 0.508977  [32032/60000]\n",
      "Epoch 1/20, loss: 0.385887  [38432/60000]\n",
      "Epoch 1/20, loss: 0.535089  [44832/60000]\n",
      "Epoch 1/20, loss: 0.378129  [51232/60000]\n",
      "Epoch 1/20, loss: 0.593923  [57632/60000]\n",
      "Epoch 2/20, loss: 0.368038  [   32/60000]\n",
      "Epoch 2/20, loss: 0.232716  [ 6432/60000]\n",
      "Epoch 2/20, loss: 0.277870  [12832/60000]\n",
      "Epoch 2/20, loss: 0.296502  [19232/60000]\n",
      "Epoch 2/20, loss: 0.442464  [25632/60000]\n",
      "Epoch 2/20, loss: 0.444699  [32032/60000]\n",
      "Epoch 2/20, loss: 0.307577  [38432/60000]\n",
      "Epoch 2/20, loss: 0.544428  [44832/60000]\n",
      "Epoch 2/20, loss: 0.382542  [51232/60000]\n",
      "Epoch 2/20, loss: 0.513483  [57632/60000]\n",
      "Epoch 3/20, loss: 0.297225  [   32/60000]\n",
      "Epoch 3/20, loss: 0.259992  [ 6432/60000]\n",
      "Epoch 3/20, loss: 0.237629  [12832/60000]\n",
      "Epoch 3/20, loss: 0.274188  [19232/60000]\n",
      "Epoch 3/20, loss: 0.476684  [25632/60000]\n",
      "Epoch 3/20, loss: 0.530580  [32032/60000]\n",
      "Epoch 3/20, loss: 0.219855  [38432/60000]\n",
      "Epoch 3/20, loss: 0.561385  [44832/60000]\n",
      "Epoch 3/20, loss: 0.235090  [51232/60000]\n",
      "Epoch 3/20, loss: 0.582021  [57632/60000]\n",
      "Epoch 4/20, loss: 0.320063  [   32/60000]\n",
      "Epoch 4/20, loss: 0.332574  [ 6432/60000]\n",
      "Epoch 4/20, loss: 0.241061  [12832/60000]\n",
      "Epoch 4/20, loss: 0.237906  [19232/60000]\n",
      "Epoch 4/20, loss: 0.434789  [25632/60000]\n",
      "Epoch 4/20, loss: 0.572610  [32032/60000]\n",
      "Epoch 4/20, loss: 0.226991  [38432/60000]\n",
      "Epoch 4/20, loss: 0.472367  [44832/60000]\n",
      "Epoch 4/20, loss: 0.230111  [51232/60000]\n",
      "Epoch 4/20, loss: 0.409372  [57632/60000]\n",
      "Epoch 5/20, loss: 0.274799  [   32/60000]\n",
      "Epoch 5/20, loss: 0.242996  [ 6432/60000]\n",
      "Epoch 5/20, loss: 0.272094  [12832/60000]\n",
      "Epoch 5/20, loss: 0.296326  [19232/60000]\n",
      "Epoch 5/20, loss: 0.473604  [25632/60000]\n",
      "Epoch 5/20, loss: 0.390551  [32032/60000]\n",
      "Epoch 5/20, loss: 0.247986  [38432/60000]\n",
      "Epoch 5/20, loss: 0.642183  [44832/60000]\n",
      "Epoch 5/20, loss: 0.261806  [51232/60000]\n",
      "Epoch 5/20, loss: 0.380514  [57632/60000]\n",
      "Epoch 6/20, loss: 0.264635  [   32/60000]\n",
      "Epoch 6/20, loss: 0.194762  [ 6432/60000]\n",
      "Epoch 6/20, loss: 0.271063  [12832/60000]\n",
      "Epoch 6/20, loss: 0.284466  [19232/60000]\n",
      "Epoch 6/20, loss: 0.414183  [25632/60000]\n",
      "Epoch 6/20, loss: 0.410162  [32032/60000]\n",
      "Epoch 6/20, loss: 0.300853  [38432/60000]\n",
      "Epoch 6/20, loss: 0.435275  [44832/60000]\n",
      "Epoch 6/20, loss: 0.216754  [51232/60000]\n",
      "Epoch 6/20, loss: 0.351743  [57632/60000]\n",
      "Epoch 7/20, loss: 0.212502  [   32/60000]\n",
      "Epoch 7/20, loss: 0.221199  [ 6432/60000]\n",
      "Epoch 7/20, loss: 0.284969  [12832/60000]\n",
      "Epoch 7/20, loss: 0.246998  [19232/60000]\n",
      "Epoch 7/20, loss: 0.524514  [25632/60000]\n",
      "Epoch 7/20, loss: 0.453161  [32032/60000]\n",
      "Epoch 7/20, loss: 0.337354  [38432/60000]\n",
      "Epoch 7/20, loss: 0.498115  [44832/60000]\n",
      "Epoch 7/20, loss: 0.225932  [51232/60000]\n",
      "Epoch 7/20, loss: 0.362979  [57632/60000]\n",
      "Epoch 8/20, loss: 0.241957  [   32/60000]\n",
      "Epoch 8/20, loss: 0.201945  [ 6432/60000]\n",
      "Epoch 8/20, loss: 0.306497  [12832/60000]\n",
      "Epoch 8/20, loss: 0.194350  [19232/60000]\n",
      "Epoch 8/20, loss: 0.319960  [25632/60000]\n",
      "Epoch 8/20, loss: 0.426319  [32032/60000]\n",
      "Epoch 8/20, loss: 0.227272  [38432/60000]\n",
      "Epoch 8/20, loss: 0.616487  [44832/60000]\n",
      "Epoch 8/20, loss: 0.250174  [51232/60000]\n",
      "Epoch 8/20, loss: 0.377414  [57632/60000]\n",
      "Epoch 9/20, loss: 0.368774  [   32/60000]\n",
      "Epoch 9/20, loss: 0.222767  [ 6432/60000]\n",
      "Epoch 9/20, loss: 0.272795  [12832/60000]\n",
      "Epoch 9/20, loss: 0.122577  [19232/60000]\n",
      "Epoch 9/20, loss: 0.255097  [25632/60000]\n",
      "Epoch 9/20, loss: 0.352588  [32032/60000]\n",
      "Epoch 9/20, loss: 0.237340  [38432/60000]\n",
      "Epoch 9/20, loss: 0.421347  [44832/60000]\n",
      "Epoch 9/20, loss: 0.189237  [51232/60000]\n",
      "Epoch 9/20, loss: 0.427061  [57632/60000]\n",
      "Epoch 10/20, loss: 0.319194  [   32/60000]\n",
      "Epoch 10/20, loss: 0.262589  [ 6432/60000]\n",
      "Epoch 10/20, loss: 0.193264  [12832/60000]\n",
      "Epoch 10/20, loss: 0.202482  [19232/60000]\n",
      "Epoch 10/20, loss: 0.333337  [25632/60000]\n",
      "Epoch 10/20, loss: 0.437076  [32032/60000]\n",
      "Epoch 10/20, loss: 0.278895  [38432/60000]\n",
      "Epoch 10/20, loss: 0.535895  [44832/60000]\n",
      "Epoch 10/20, loss: 0.161815  [51232/60000]\n",
      "Epoch 10/20, loss: 0.292580  [57632/60000]\n",
      "Epoch 11/20, loss: 0.183327  [   32/60000]\n",
      "Epoch 11/20, loss: 0.161196  [ 6432/60000]\n",
      "Epoch 11/20, loss: 0.253137  [12832/60000]\n",
      "Epoch 11/20, loss: 0.210215  [19232/60000]\n",
      "Epoch 11/20, loss: 0.380115  [25632/60000]\n",
      "Epoch 11/20, loss: 0.355409  [32032/60000]\n",
      "Epoch 11/20, loss: 0.182829  [38432/60000]\n",
      "Epoch 11/20, loss: 0.547157  [44832/60000]\n",
      "Epoch 11/20, loss: 0.199564  [51232/60000]\n",
      "Epoch 11/20, loss: 0.239689  [57632/60000]\n",
      "Epoch 12/20, loss: 0.118561  [   32/60000]\n",
      "Epoch 12/20, loss: 0.175860  [ 6432/60000]\n",
      "Epoch 12/20, loss: 0.262112  [12832/60000]\n",
      "Epoch 12/20, loss: 0.348233  [19232/60000]\n",
      "Epoch 12/20, loss: 0.375978  [25632/60000]\n",
      "Epoch 12/20, loss: 0.402099  [32032/60000]\n",
      "Epoch 12/20, loss: 0.282448  [38432/60000]\n",
      "Epoch 12/20, loss: 0.425412  [44832/60000]\n",
      "Epoch 12/20, loss: 0.252241  [51232/60000]\n",
      "Epoch 12/20, loss: 0.245600  [57632/60000]\n",
      "Epoch 13/20, loss: 0.223015  [   32/60000]\n",
      "Epoch 13/20, loss: 0.200703  [ 6432/60000]\n",
      "Epoch 13/20, loss: 0.281649  [12832/60000]\n",
      "Epoch 13/20, loss: 0.198604  [19232/60000]\n",
      "Epoch 13/20, loss: 0.333997  [25632/60000]\n",
      "Epoch 13/20, loss: 0.356021  [32032/60000]\n",
      "Epoch 13/20, loss: 0.175775  [38432/60000]\n",
      "Epoch 13/20, loss: 0.761969  [44832/60000]\n",
      "Epoch 13/20, loss: 0.194283  [51232/60000]\n",
      "Epoch 13/20, loss: 0.229044  [57632/60000]\n",
      "Epoch 14/20, loss: 0.235101  [   32/60000]\n",
      "Epoch 14/20, loss: 0.207816  [ 6432/60000]\n",
      "Epoch 14/20, loss: 0.466066  [12832/60000]\n",
      "Epoch 14/20, loss: 0.203962  [19232/60000]\n",
      "Epoch 14/20, loss: 0.212298  [25632/60000]\n",
      "Epoch 14/20, loss: 0.298368  [32032/60000]\n",
      "Epoch 14/20, loss: 0.202315  [38432/60000]\n",
      "Epoch 14/20, loss: 0.552787  [44832/60000]\n",
      "Epoch 14/20, loss: 0.187571  [51232/60000]\n",
      "Epoch 14/20, loss: 0.258854  [57632/60000]\n",
      "Epoch 15/20, loss: 0.171803  [   32/60000]\n",
      "Epoch 15/20, loss: 0.167071  [ 6432/60000]\n",
      "Epoch 15/20, loss: 0.436276  [12832/60000]\n",
      "Epoch 15/20, loss: 0.311812  [19232/60000]\n",
      "Epoch 15/20, loss: 0.283124  [25632/60000]\n",
      "Epoch 15/20, loss: 0.385486  [32032/60000]\n",
      "Epoch 15/20, loss: 0.211709  [38432/60000]\n",
      "Epoch 15/20, loss: 0.557469  [44832/60000]\n",
      "Epoch 15/20, loss: 0.175073  [51232/60000]\n",
      "Epoch 15/20, loss: 0.318244  [57632/60000]\n",
      "Epoch 16/20, loss: 0.171577  [   32/60000]\n",
      "Epoch 16/20, loss: 0.175715  [ 6432/60000]\n",
      "Epoch 16/20, loss: 0.262286  [12832/60000]\n",
      "Epoch 16/20, loss: 0.218104  [19232/60000]\n",
      "Epoch 16/20, loss: 0.246401  [25632/60000]\n",
      "Epoch 16/20, loss: 0.347426  [32032/60000]\n",
      "Epoch 16/20, loss: 0.218925  [38432/60000]\n",
      "Epoch 16/20, loss: 0.463482  [44832/60000]\n",
      "Epoch 16/20, loss: 0.186881  [51232/60000]\n",
      "Epoch 16/20, loss: 0.316614  [57632/60000]\n",
      "Epoch 17/20, loss: 0.290542  [   32/60000]\n",
      "Epoch 17/20, loss: 0.121730  [ 6432/60000]\n",
      "Epoch 17/20, loss: 0.264463  [12832/60000]\n",
      "Epoch 17/20, loss: 0.200031  [19232/60000]\n",
      "Epoch 17/20, loss: 0.327943  [25632/60000]\n",
      "Epoch 17/20, loss: 0.303834  [32032/60000]\n",
      "Epoch 17/20, loss: 0.240913  [38432/60000]\n",
      "Epoch 17/20, loss: 0.513039  [44832/60000]\n",
      "Epoch 17/20, loss: 0.188089  [51232/60000]\n",
      "Epoch 17/20, loss: 0.230344  [57632/60000]\n",
      "Epoch 18/20, loss: 0.206184  [   32/60000]\n",
      "Epoch 18/20, loss: 0.160291  [ 6432/60000]\n",
      "Epoch 18/20, loss: 0.398198  [12832/60000]\n",
      "Epoch 18/20, loss: 0.206033  [19232/60000]\n",
      "Epoch 18/20, loss: 0.246395  [25632/60000]\n",
      "Epoch 18/20, loss: 0.357066  [32032/60000]\n",
      "Epoch 18/20, loss: 0.235839  [38432/60000]\n",
      "Epoch 18/20, loss: 0.534664  [44832/60000]\n",
      "Epoch 18/20, loss: 0.197573  [51232/60000]\n",
      "Epoch 18/20, loss: 0.345268  [57632/60000]\n",
      "Epoch 19/20, loss: 0.200532  [   32/60000]\n",
      "Epoch 19/20, loss: 0.191855  [ 6432/60000]\n",
      "Epoch 19/20, loss: 0.411663  [12832/60000]\n",
      "Epoch 19/20, loss: 0.197659  [19232/60000]\n",
      "Epoch 19/20, loss: 0.198753  [25632/60000]\n",
      "Epoch 19/20, loss: 0.347482  [32032/60000]\n",
      "Epoch 19/20, loss: 0.222327  [38432/60000]\n",
      "Epoch 19/20, loss: 0.479957  [44832/60000]\n",
      "Epoch 19/20, loss: 0.180283  [51232/60000]\n",
      "Epoch 19/20, loss: 0.336906  [57632/60000]\n",
      "Epoch 20/20, loss: 0.177261  [   32/60000]\n",
      "Epoch 20/20, loss: 0.175382  [ 6432/60000]\n",
      "Epoch 20/20, loss: 0.239108  [12832/60000]\n",
      "Epoch 20/20, loss: 0.191152  [19232/60000]\n",
      "Epoch 20/20, loss: 0.187106  [25632/60000]\n",
      "Epoch 20/20, loss: 0.189994  [32032/60000]\n",
      "Epoch 20/20, loss: 0.268874  [38432/60000]\n",
      "Epoch 20/20, loss: 0.459281  [44832/60000]\n",
      "Epoch 20/20, loss: 0.159880  [51232/60000]\n",
      "Epoch 20/20, loss: 0.274677  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.345596 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch 1/20, loss: 0.111828  [   32/60000]\n",
      "Epoch 1/20, loss: 0.129244  [ 6432/60000]\n",
      "Epoch 1/20, loss: 0.302640  [12832/60000]\n",
      "Epoch 1/20, loss: 0.260520  [19232/60000]\n",
      "Epoch 1/20, loss: 0.257155  [25632/60000]\n",
      "Epoch 1/20, loss: 0.442244  [32032/60000]\n",
      "Epoch 1/20, loss: 0.256760  [38432/60000]\n",
      "Epoch 1/20, loss: 0.339293  [44832/60000]\n",
      "Epoch 1/20, loss: 0.121584  [51232/60000]\n",
      "Epoch 1/20, loss: 0.241820  [57632/60000]\n",
      "Epoch 2/20, loss: 0.124516  [   32/60000]\n",
      "Epoch 2/20, loss: 0.149393  [ 6432/60000]\n",
      "Epoch 2/20, loss: 0.285585  [12832/60000]\n",
      "Epoch 2/20, loss: 0.197376  [19232/60000]\n",
      "Epoch 2/20, loss: 0.210737  [25632/60000]\n",
      "Epoch 2/20, loss: 0.321646  [32032/60000]\n",
      "Epoch 2/20, loss: 0.197180  [38432/60000]\n",
      "Epoch 2/20, loss: 0.522398  [44832/60000]\n",
      "Epoch 2/20, loss: 0.198714  [51232/60000]\n",
      "Epoch 2/20, loss: 0.275629  [57632/60000]\n",
      "Epoch 3/20, loss: 0.250498  [   32/60000]\n",
      "Epoch 3/20, loss: 0.118705  [ 6432/60000]\n",
      "Epoch 3/20, loss: 0.291053  [12832/60000]\n",
      "Epoch 3/20, loss: 0.173764  [19232/60000]\n",
      "Epoch 3/20, loss: 0.263108  [25632/60000]\n",
      "Epoch 3/20, loss: 0.310944  [32032/60000]\n",
      "Epoch 3/20, loss: 0.228415  [38432/60000]\n",
      "Epoch 3/20, loss: 0.281796  [44832/60000]\n",
      "Epoch 3/20, loss: 0.238869  [51232/60000]\n",
      "Epoch 3/20, loss: 0.165876  [57632/60000]\n",
      "Epoch 4/20, loss: 0.191619  [   32/60000]\n",
      "Epoch 4/20, loss: 0.132409  [ 6432/60000]\n",
      "Epoch 4/20, loss: 0.302253  [12832/60000]\n",
      "Epoch 4/20, loss: 0.224477  [19232/60000]\n",
      "Epoch 4/20, loss: 0.202041  [25632/60000]\n",
      "Epoch 4/20, loss: 0.239408  [32032/60000]\n",
      "Epoch 4/20, loss: 0.193598  [38432/60000]\n",
      "Epoch 4/20, loss: 0.439108  [44832/60000]\n",
      "Epoch 4/20, loss: 0.149767  [51232/60000]\n",
      "Epoch 4/20, loss: 0.278868  [57632/60000]\n",
      "Epoch 5/20, loss: 0.242984  [   32/60000]\n",
      "Epoch 5/20, loss: 0.150105  [ 6432/60000]\n",
      "Epoch 5/20, loss: 0.233110  [12832/60000]\n",
      "Epoch 5/20, loss: 0.169366  [19232/60000]\n",
      "Epoch 5/20, loss: 0.150363  [25632/60000]\n",
      "Epoch 5/20, loss: 0.225686  [32032/60000]\n",
      "Epoch 5/20, loss: 0.228615  [38432/60000]\n",
      "Epoch 5/20, loss: 0.397899  [44832/60000]\n",
      "Epoch 5/20, loss: 0.151851  [51232/60000]\n",
      "Epoch 5/20, loss: 0.269978  [57632/60000]\n",
      "Epoch 6/20, loss: 0.211054  [   32/60000]\n",
      "Epoch 6/20, loss: 0.114749  [ 6432/60000]\n",
      "Epoch 6/20, loss: 0.341163  [12832/60000]\n",
      "Epoch 6/20, loss: 0.194435  [19232/60000]\n",
      "Epoch 6/20, loss: 0.207373  [25632/60000]\n",
      "Epoch 6/20, loss: 0.255462  [32032/60000]\n",
      "Epoch 6/20, loss: 0.169832  [38432/60000]\n",
      "Epoch 6/20, loss: 0.375479  [44832/60000]\n",
      "Epoch 6/20, loss: 0.154180  [51232/60000]\n",
      "Epoch 6/20, loss: 0.289009  [57632/60000]\n",
      "Epoch 7/20, loss: 0.167929  [   32/60000]\n",
      "Epoch 7/20, loss: 0.107891  [ 6432/60000]\n",
      "Epoch 7/20, loss: 0.276337  [12832/60000]\n",
      "Epoch 7/20, loss: 0.175090  [19232/60000]\n",
      "Epoch 7/20, loss: 0.178941  [25632/60000]\n",
      "Epoch 7/20, loss: 0.283691  [32032/60000]\n",
      "Epoch 7/20, loss: 0.219481  [38432/60000]\n",
      "Epoch 7/20, loss: 0.300620  [44832/60000]\n",
      "Epoch 7/20, loss: 0.153890  [51232/60000]\n",
      "Epoch 7/20, loss: 0.231046  [57632/60000]\n",
      "Epoch 8/20, loss: 0.272927  [   32/60000]\n",
      "Epoch 8/20, loss: 0.131855  [ 6432/60000]\n",
      "Epoch 8/20, loss: 0.225600  [12832/60000]\n",
      "Epoch 8/20, loss: 0.234521  [19232/60000]\n",
      "Epoch 8/20, loss: 0.214506  [25632/60000]\n",
      "Epoch 8/20, loss: 0.307577  [32032/60000]\n",
      "Epoch 8/20, loss: 0.164237  [38432/60000]\n",
      "Epoch 8/20, loss: 0.455740  [44832/60000]\n",
      "Epoch 8/20, loss: 0.159540  [51232/60000]\n",
      "Epoch 8/20, loss: 0.204252  [57632/60000]\n",
      "Epoch 9/20, loss: 0.316144  [   32/60000]\n",
      "Epoch 9/20, loss: 0.112459  [ 6432/60000]\n",
      "Epoch 9/20, loss: 0.306614  [12832/60000]\n",
      "Epoch 9/20, loss: 0.121855  [19232/60000]\n",
      "Epoch 9/20, loss: 0.156933  [25632/60000]\n",
      "Epoch 9/20, loss: 0.267251  [32032/60000]\n",
      "Epoch 9/20, loss: 0.235129  [38432/60000]\n",
      "Epoch 9/20, loss: 0.363655  [44832/60000]\n",
      "Epoch 9/20, loss: 0.208832  [51232/60000]\n",
      "Epoch 9/20, loss: 0.328166  [57632/60000]\n",
      "Epoch 10/20, loss: 0.222983  [   32/60000]\n",
      "Epoch 10/20, loss: 0.204073  [ 6432/60000]\n",
      "Epoch 10/20, loss: 0.293142  [12832/60000]\n",
      "Epoch 10/20, loss: 0.140787  [19232/60000]\n",
      "Epoch 10/20, loss: 0.217722  [25632/60000]\n",
      "Epoch 10/20, loss: 0.216797  [32032/60000]\n",
      "Epoch 10/20, loss: 0.184263  [38432/60000]\n",
      "Epoch 10/20, loss: 0.372622  [44832/60000]\n",
      "Epoch 10/20, loss: 0.199917  [51232/60000]\n",
      "Epoch 10/20, loss: 0.338441  [57632/60000]\n",
      "Epoch 11/20, loss: 0.193024  [   32/60000]\n",
      "Epoch 11/20, loss: 0.104615  [ 6432/60000]\n",
      "Epoch 11/20, loss: 0.220133  [12832/60000]\n",
      "Epoch 11/20, loss: 0.122968  [19232/60000]\n",
      "Epoch 11/20, loss: 0.150976  [25632/60000]\n",
      "Epoch 11/20, loss: 0.334920  [32032/60000]\n",
      "Epoch 11/20, loss: 0.135521  [38432/60000]\n",
      "Epoch 11/20, loss: 0.373903  [44832/60000]\n",
      "Epoch 11/20, loss: 0.234211  [51232/60000]\n",
      "Epoch 11/20, loss: 0.293095  [57632/60000]\n",
      "Epoch 12/20, loss: 0.256359  [   32/60000]\n",
      "Epoch 12/20, loss: 0.181670  [ 6432/60000]\n",
      "Epoch 12/20, loss: 0.248426  [12832/60000]\n",
      "Epoch 12/20, loss: 0.195119  [19232/60000]\n",
      "Epoch 12/20, loss: 0.391762  [25632/60000]\n",
      "Epoch 12/20, loss: 0.310617  [32032/60000]\n",
      "Epoch 12/20, loss: 0.175352  [38432/60000]\n",
      "Epoch 12/20, loss: 0.263243  [44832/60000]\n",
      "Epoch 12/20, loss: 0.221739  [51232/60000]\n",
      "Epoch 12/20, loss: 0.213883  [57632/60000]\n",
      "Epoch 13/20, loss: 0.173744  [   32/60000]\n",
      "Epoch 13/20, loss: 0.123902  [ 6432/60000]\n",
      "Epoch 13/20, loss: 0.232881  [12832/60000]\n",
      "Epoch 13/20, loss: 0.205811  [19232/60000]\n",
      "Epoch 13/20, loss: 0.144448  [25632/60000]\n",
      "Epoch 13/20, loss: 0.226319  [32032/60000]\n",
      "Epoch 13/20, loss: 0.250847  [38432/60000]\n",
      "Epoch 13/20, loss: 0.351022  [44832/60000]\n",
      "Epoch 13/20, loss: 0.146702  [51232/60000]\n",
      "Epoch 13/20, loss: 0.168464  [57632/60000]\n",
      "Epoch 14/20, loss: 0.122333  [   32/60000]\n",
      "Epoch 14/20, loss: 0.096415  [ 6432/60000]\n",
      "Epoch 14/20, loss: 0.289256  [12832/60000]\n",
      "Epoch 14/20, loss: 0.287132  [19232/60000]\n",
      "Epoch 14/20, loss: 0.230369  [25632/60000]\n",
      "Epoch 14/20, loss: 0.272181  [32032/60000]\n",
      "Epoch 14/20, loss: 0.232750  [38432/60000]\n",
      "Epoch 14/20, loss: 0.381670  [44832/60000]\n",
      "Epoch 14/20, loss: 0.131181  [51232/60000]\n",
      "Epoch 14/20, loss: 0.194434  [57632/60000]\n",
      "Epoch 15/20, loss: 0.284232  [   32/60000]\n",
      "Epoch 15/20, loss: 0.110276  [ 6432/60000]\n",
      "Epoch 15/20, loss: 0.194992  [12832/60000]\n",
      "Epoch 15/20, loss: 0.193309  [19232/60000]\n",
      "Epoch 15/20, loss: 0.969199  [25632/60000]\n",
      "Epoch 15/20, loss: 0.269766  [32032/60000]\n",
      "Epoch 15/20, loss: 0.270388  [38432/60000]\n",
      "Epoch 15/20, loss: 0.210483  [44832/60000]\n",
      "Epoch 15/20, loss: 0.168434  [51232/60000]\n",
      "Epoch 15/20, loss: 0.259037  [57632/60000]\n",
      "Epoch 16/20, loss: 0.126333  [   32/60000]\n",
      "Epoch 16/20, loss: 0.116146  [ 6432/60000]\n",
      "Epoch 16/20, loss: 0.154856  [12832/60000]\n",
      "Epoch 16/20, loss: 0.106962  [19232/60000]\n",
      "Epoch 16/20, loss: 0.138141  [25632/60000]\n",
      "Epoch 16/20, loss: 0.368926  [32032/60000]\n",
      "Epoch 16/20, loss: 0.293726  [38432/60000]\n",
      "Epoch 16/20, loss: 0.274097  [44832/60000]\n",
      "Epoch 16/20, loss: 0.124582  [51232/60000]\n",
      "Epoch 16/20, loss: 0.248409  [57632/60000]\n",
      "Epoch 17/20, loss: 0.147365  [   32/60000]\n",
      "Epoch 17/20, loss: 0.210595  [ 6432/60000]\n",
      "Epoch 17/20, loss: 0.270129  [12832/60000]\n",
      "Epoch 17/20, loss: 0.335991  [19232/60000]\n",
      "Epoch 17/20, loss: 0.329328  [25632/60000]\n",
      "Epoch 17/20, loss: 0.329671  [32032/60000]\n",
      "Epoch 17/20, loss: 0.228014  [38432/60000]\n",
      "Epoch 17/20, loss: 0.330781  [44832/60000]\n",
      "Epoch 17/20, loss: 0.139346  [51232/60000]\n",
      "Epoch 17/20, loss: 0.287696  [57632/60000]\n",
      "Epoch 18/20, loss: 0.130340  [   32/60000]\n",
      "Epoch 18/20, loss: 0.109840  [ 6432/60000]\n",
      "Epoch 18/20, loss: 0.359377  [12832/60000]\n",
      "Epoch 18/20, loss: 0.154620  [19232/60000]\n",
      "Epoch 18/20, loss: 0.290673  [25632/60000]\n",
      "Epoch 18/20, loss: 0.277415  [32032/60000]\n",
      "Epoch 18/20, loss: 0.238359  [38432/60000]\n",
      "Epoch 18/20, loss: 0.354675  [44832/60000]\n",
      "Epoch 18/20, loss: 0.222055  [51232/60000]\n",
      "Epoch 18/20, loss: 0.118524  [57632/60000]\n",
      "Epoch 19/20, loss: 0.211852  [   32/60000]\n",
      "Epoch 19/20, loss: 0.130568  [ 6432/60000]\n",
      "Epoch 19/20, loss: 0.292146  [12832/60000]\n",
      "Epoch 19/20, loss: 0.253200  [19232/60000]\n",
      "Epoch 19/20, loss: 0.222741  [25632/60000]\n",
      "Epoch 19/20, loss: 0.289918  [32032/60000]\n",
      "Epoch 19/20, loss: 0.339396  [38432/60000]\n",
      "Epoch 19/20, loss: 0.397603  [44832/60000]\n",
      "Epoch 19/20, loss: 0.120261  [51232/60000]\n",
      "Epoch 19/20, loss: 0.185833  [57632/60000]\n",
      "Epoch 20/20, loss: 0.169182  [   32/60000]\n",
      "Epoch 20/20, loss: 0.181993  [ 6432/60000]\n",
      "Epoch 20/20, loss: 0.281262  [12832/60000]\n",
      "Epoch 20/20, loss: 0.389212  [19232/60000]\n",
      "Epoch 20/20, loss: 0.220264  [25632/60000]\n",
      "Epoch 20/20, loss: 0.386977  [32032/60000]\n",
      "Epoch 20/20, loss: 0.128764  [38432/60000]\n",
      "Epoch 20/20, loss: 0.350612  [44832/60000]\n",
      "Epoch 20/20, loss: 0.177862  [51232/60000]\n",
      "Epoch 20/20, loss: 0.352477  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.407568 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch 1/20, loss: 0.063606  [   32/60000]\n",
      "Epoch 1/20, loss: 0.089486  [ 6432/60000]\n",
      "Epoch 1/20, loss: 0.293968  [12832/60000]\n",
      "Epoch 1/20, loss: 0.156218  [19232/60000]\n",
      "Epoch 1/20, loss: 0.150337  [25632/60000]\n",
      "Epoch 1/20, loss: 0.333173  [32032/60000]\n",
      "Epoch 1/20, loss: 0.132524  [38432/60000]\n",
      "Epoch 1/20, loss: 0.270098  [44832/60000]\n",
      "Epoch 1/20, loss: 0.133892  [51232/60000]\n",
      "Epoch 1/20, loss: 0.188346  [57632/60000]\n",
      "Epoch 2/20, loss: 0.139316  [   32/60000]\n",
      "Epoch 2/20, loss: 0.089419  [ 6432/60000]\n",
      "Epoch 2/20, loss: 0.301128  [12832/60000]\n",
      "Epoch 2/20, loss: 0.180794  [19232/60000]\n",
      "Epoch 2/20, loss: 0.121141  [25632/60000]\n",
      "Epoch 2/20, loss: 0.264777  [32032/60000]\n",
      "Epoch 2/20, loss: 0.159299  [38432/60000]\n",
      "Epoch 2/20, loss: 0.421609  [44832/60000]\n",
      "Epoch 2/20, loss: 0.143366  [51232/60000]\n",
      "Epoch 2/20, loss: 0.218037  [57632/60000]\n",
      "Epoch 3/20, loss: 0.078627  [   32/60000]\n",
      "Epoch 3/20, loss: 0.068393  [ 6432/60000]\n",
      "Epoch 3/20, loss: 0.221845  [12832/60000]\n",
      "Epoch 3/20, loss: 0.176047  [19232/60000]\n",
      "Epoch 3/20, loss: 0.129575  [25632/60000]\n",
      "Epoch 3/20, loss: 0.219433  [32032/60000]\n",
      "Epoch 3/20, loss: 0.200554  [38432/60000]\n",
      "Epoch 3/20, loss: 0.987556  [44832/60000]\n",
      "Epoch 3/20, loss: 0.167565  [51232/60000]\n",
      "Epoch 3/20, loss: 0.212589  [57632/60000]\n",
      "Epoch 4/20, loss: 0.193808  [   32/60000]\n",
      "Epoch 4/20, loss: 0.099683  [ 6432/60000]\n",
      "Epoch 4/20, loss: 0.264091  [12832/60000]\n",
      "Epoch 4/20, loss: 0.101698  [19232/60000]\n",
      "Epoch 4/20, loss: 0.310194  [25632/60000]\n",
      "Epoch 4/20, loss: 0.668193  [32032/60000]\n",
      "Epoch 4/20, loss: 0.229357  [38432/60000]\n",
      "Epoch 4/20, loss: 0.232539  [44832/60000]\n",
      "Epoch 4/20, loss: 0.107133  [51232/60000]\n",
      "Epoch 4/20, loss: 0.160930  [57632/60000]\n",
      "Epoch 5/20, loss: 0.156431  [   32/60000]\n",
      "Epoch 5/20, loss: 0.088159  [ 6432/60000]\n",
      "Epoch 5/20, loss: 0.280494  [12832/60000]\n",
      "Epoch 5/20, loss: 0.338196  [19232/60000]\n",
      "Epoch 5/20, loss: 0.191884  [25632/60000]\n",
      "Epoch 5/20, loss: 0.437320  [32032/60000]\n",
      "Epoch 5/20, loss: 0.188452  [38432/60000]\n",
      "Epoch 5/20, loss: 0.295764  [44832/60000]\n",
      "Epoch 5/20, loss: 0.117306  [51232/60000]\n",
      "Epoch 5/20, loss: 0.153348  [57632/60000]\n",
      "Epoch 6/20, loss: 0.118839  [   32/60000]\n",
      "Epoch 6/20, loss: 0.121835  [ 6432/60000]\n",
      "Epoch 6/20, loss: 0.198425  [12832/60000]\n",
      "Epoch 6/20, loss: 0.169444  [19232/60000]\n",
      "Epoch 6/20, loss: 0.136056  [25632/60000]\n",
      "Epoch 6/20, loss: 0.240392  [32032/60000]\n",
      "Epoch 6/20, loss: 0.140602  [38432/60000]\n",
      "Epoch 6/20, loss: 0.252150  [44832/60000]\n",
      "Epoch 6/20, loss: 0.159492  [51232/60000]\n",
      "Epoch 6/20, loss: 0.281654  [57632/60000]\n",
      "Epoch 7/20, loss: 0.089576  [   32/60000]\n",
      "Epoch 7/20, loss: 0.083697  [ 6432/60000]\n",
      "Epoch 7/20, loss: 0.322819  [12832/60000]\n",
      "Epoch 7/20, loss: 0.140531  [19232/60000]\n",
      "Epoch 7/20, loss: 0.218030  [25632/60000]\n",
      "Epoch 7/20, loss: 0.313549  [32032/60000]\n",
      "Epoch 7/20, loss: 0.175423  [38432/60000]\n",
      "Epoch 7/20, loss: 0.232689  [44832/60000]\n",
      "Epoch 7/20, loss: 0.084648  [51232/60000]\n",
      "Epoch 7/20, loss: 0.183889  [57632/60000]\n",
      "Epoch 8/20, loss: 0.192911  [   32/60000]\n",
      "Epoch 8/20, loss: 0.058046  [ 6432/60000]\n",
      "Epoch 8/20, loss: 0.406126  [12832/60000]\n",
      "Epoch 8/20, loss: 0.119151  [19232/60000]\n",
      "Epoch 8/20, loss: 0.246470  [25632/60000]\n",
      "Epoch 8/20, loss: 0.274754  [32032/60000]\n",
      "Epoch 8/20, loss: 0.242812  [38432/60000]\n",
      "Epoch 8/20, loss: 0.272034  [44832/60000]\n",
      "Epoch 8/20, loss: 0.143080  [51232/60000]\n",
      "Epoch 8/20, loss: 0.158717  [57632/60000]\n",
      "Epoch 9/20, loss: 0.114969  [   32/60000]\n",
      "Epoch 9/20, loss: 0.092768  [ 6432/60000]\n",
      "Epoch 9/20, loss: 0.233558  [12832/60000]\n",
      "Epoch 9/20, loss: 0.104341  [19232/60000]\n",
      "Epoch 9/20, loss: 0.178687  [25632/60000]\n",
      "Epoch 9/20, loss: 0.369423  [32032/60000]\n",
      "Epoch 9/20, loss: 0.200443  [38432/60000]\n",
      "Epoch 9/20, loss: 0.241414  [44832/60000]\n",
      "Epoch 9/20, loss: 0.214187  [51232/60000]\n",
      "Epoch 9/20, loss: 0.175611  [57632/60000]\n",
      "Epoch 10/20, loss: 0.105520  [   32/60000]\n",
      "Epoch 10/20, loss: 0.156041  [ 6432/60000]\n",
      "Epoch 10/20, loss: 0.412271  [12832/60000]\n",
      "Epoch 10/20, loss: 0.110982  [19232/60000]\n",
      "Epoch 10/20, loss: 0.720436  [25632/60000]\n",
      "Epoch 10/20, loss: 0.272787  [32032/60000]\n",
      "Epoch 10/20, loss: 0.185784  [38432/60000]\n",
      "Epoch 10/20, loss: 0.416522  [44832/60000]\n",
      "Epoch 10/20, loss: 0.144980  [51232/60000]\n",
      "Epoch 10/20, loss: 0.133681  [57632/60000]\n",
      "Epoch 11/20, loss: 0.135325  [   32/60000]\n",
      "Epoch 11/20, loss: 0.109284  [ 6432/60000]\n",
      "Epoch 11/20, loss: 0.244337  [12832/60000]\n",
      "Epoch 11/20, loss: 0.205931  [19232/60000]\n",
      "Epoch 11/20, loss: 0.084350  [25632/60000]\n",
      "Epoch 11/20, loss: 0.312587  [32032/60000]\n",
      "Epoch 11/20, loss: 0.201145  [38432/60000]\n",
      "Epoch 11/20, loss: 0.310151  [44832/60000]\n",
      "Epoch 11/20, loss: 0.106338  [51232/60000]\n",
      "Epoch 11/20, loss: 0.245881  [57632/60000]\n",
      "Epoch 12/20, loss: 0.195327  [   32/60000]\n",
      "Epoch 12/20, loss: 0.122661  [ 6432/60000]\n",
      "Epoch 12/20, loss: 0.179213  [12832/60000]\n",
      "Epoch 12/20, loss: 0.202467  [19232/60000]\n",
      "Epoch 12/20, loss: 0.282909  [25632/60000]\n",
      "Epoch 12/20, loss: 0.229822  [32032/60000]\n",
      "Epoch 12/20, loss: 0.180858  [38432/60000]\n",
      "Epoch 12/20, loss: 0.198295  [44832/60000]\n",
      "Epoch 12/20, loss: 0.171922  [51232/60000]\n",
      "Epoch 12/20, loss: 0.149930  [57632/60000]\n",
      "Epoch 13/20, loss: 0.197395  [   32/60000]\n",
      "Epoch 13/20, loss: 0.089419  [ 6432/60000]\n",
      "Epoch 13/20, loss: 0.156402  [12832/60000]\n",
      "Epoch 13/20, loss: 0.240666  [19232/60000]\n",
      "Epoch 13/20, loss: 0.097947  [25632/60000]\n",
      "Epoch 13/20, loss: 0.363468  [32032/60000]\n",
      "Epoch 13/20, loss: 0.118451  [38432/60000]\n",
      "Epoch 13/20, loss: 0.296667  [44832/60000]\n",
      "Epoch 13/20, loss: 0.204512  [51232/60000]\n",
      "Epoch 13/20, loss: 0.204873  [57632/60000]\n",
      "Epoch 14/20, loss: 0.092122  [   32/60000]\n",
      "Epoch 14/20, loss: 0.076134  [ 6432/60000]\n",
      "Epoch 14/20, loss: 0.196860  [12832/60000]\n",
      "Epoch 14/20, loss: 0.203897  [19232/60000]\n",
      "Epoch 14/20, loss: 0.107574  [25632/60000]\n",
      "Epoch 14/20, loss: 0.242711  [32032/60000]\n",
      "Epoch 14/20, loss: 0.312279  [38432/60000]\n",
      "Epoch 14/20, loss: 0.199669  [44832/60000]\n",
      "Epoch 14/20, loss: 0.120528  [51232/60000]\n",
      "Epoch 14/20, loss: 0.145423  [57632/60000]\n",
      "Epoch 15/20, loss: 0.326775  [   32/60000]\n",
      "Epoch 15/20, loss: 0.183601  [ 6432/60000]\n",
      "Epoch 15/20, loss: 0.239443  [12832/60000]\n",
      "Epoch 15/20, loss: 0.127820  [19232/60000]\n",
      "Epoch 15/20, loss: 0.113307  [25632/60000]\n",
      "Epoch 15/20, loss: 0.297712  [32032/60000]\n",
      "Epoch 15/20, loss: 0.191039  [38432/60000]\n",
      "Epoch 15/20, loss: 0.231701  [44832/60000]\n",
      "Epoch 15/20, loss: 0.087353  [51232/60000]\n",
      "Epoch 15/20, loss: 0.218499  [57632/60000]\n",
      "Epoch 16/20, loss: 0.194462  [   32/60000]\n",
      "Epoch 16/20, loss: 0.129603  [ 6432/60000]\n",
      "Epoch 16/20, loss: 0.400200  [12832/60000]\n",
      "Epoch 16/20, loss: 0.137547  [19232/60000]\n",
      "Epoch 16/20, loss: 0.238734  [25632/60000]\n",
      "Epoch 16/20, loss: 0.285444  [32032/60000]\n",
      "Epoch 16/20, loss: 0.153551  [38432/60000]\n",
      "Epoch 16/20, loss: 0.395031  [44832/60000]\n",
      "Epoch 16/20, loss: 0.176793  [51232/60000]\n",
      "Epoch 16/20, loss: 0.158972  [57632/60000]\n",
      "Epoch 17/20, loss: 0.164411  [   32/60000]\n",
      "Epoch 17/20, loss: 0.108354  [ 6432/60000]\n",
      "Epoch 17/20, loss: 0.269902  [12832/60000]\n",
      "Epoch 17/20, loss: 0.136882  [19232/60000]\n",
      "Epoch 17/20, loss: 0.065691  [25632/60000]\n",
      "Epoch 17/20, loss: 0.250445  [32032/60000]\n",
      "Epoch 17/20, loss: 0.527230  [38432/60000]\n",
      "Epoch 17/20, loss: 0.278998  [44832/60000]\n",
      "Epoch 17/20, loss: 0.108970  [51232/60000]\n",
      "Epoch 17/20, loss: 0.126048  [57632/60000]\n",
      "Epoch 18/20, loss: 0.108384  [   32/60000]\n",
      "Epoch 18/20, loss: 0.073335  [ 6432/60000]\n",
      "Epoch 18/20, loss: 0.121351  [12832/60000]\n",
      "Epoch 18/20, loss: 0.196622  [19232/60000]\n",
      "Epoch 18/20, loss: 0.220921  [25632/60000]\n",
      "Epoch 18/20, loss: 0.257561  [32032/60000]\n",
      "Epoch 18/20, loss: 0.154716  [38432/60000]\n",
      "Epoch 18/20, loss: 0.269605  [44832/60000]\n",
      "Epoch 18/20, loss: 0.105487  [51232/60000]\n",
      "Epoch 18/20, loss: 0.121138  [57632/60000]\n",
      "Epoch 19/20, loss: 0.217877  [   32/60000]\n",
      "Epoch 19/20, loss: 0.104451  [ 6432/60000]\n",
      "Epoch 19/20, loss: 0.329929  [12832/60000]\n",
      "Epoch 19/20, loss: 0.142660  [19232/60000]\n",
      "Epoch 19/20, loss: 0.298679  [25632/60000]\n",
      "Epoch 19/20, loss: 0.279889  [32032/60000]\n",
      "Epoch 19/20, loss: 0.137703  [38432/60000]\n",
      "Epoch 19/20, loss: 0.320429  [44832/60000]\n",
      "Epoch 19/20, loss: 0.115486  [51232/60000]\n",
      "Epoch 19/20, loss: 0.147919  [57632/60000]\n",
      "Epoch 20/20, loss: 0.090361  [   32/60000]\n",
      "Epoch 20/20, loss: 0.085596  [ 6432/60000]\n",
      "Epoch 20/20, loss: 0.299451  [12832/60000]\n",
      "Epoch 20/20, loss: 0.053648  [19232/60000]\n",
      "Epoch 20/20, loss: 0.079791  [25632/60000]\n",
      "Epoch 20/20, loss: 0.481988  [32032/60000]\n",
      "Epoch 20/20, loss: 0.309488  [38432/60000]\n",
      "Epoch 20/20, loss: 0.203675  [44832/60000]\n",
      "Epoch 20/20, loss: 0.142093  [51232/60000]\n",
      "Epoch 20/20, loss: 0.222654  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.463967 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch 1/20, loss: 0.164595  [   32/60000]\n",
      "Epoch 1/20, loss: 0.078793  [ 6432/60000]\n",
      "Epoch 1/20, loss: 0.323676  [12832/60000]\n",
      "Epoch 1/20, loss: 0.154761  [19232/60000]\n",
      "Epoch 1/20, loss: 0.208980  [25632/60000]\n",
      "Epoch 1/20, loss: 0.323128  [32032/60000]\n",
      "Epoch 1/20, loss: 0.093232  [38432/60000]\n",
      "Epoch 1/20, loss: 0.349499  [44832/60000]\n",
      "Epoch 1/20, loss: 0.157915  [51232/60000]\n",
      "Epoch 1/20, loss: 0.319980  [57632/60000]\n",
      "Epoch 2/20, loss: 0.086089  [   32/60000]\n",
      "Epoch 2/20, loss: 0.050702  [ 6432/60000]\n",
      "Epoch 2/20, loss: 0.233118  [12832/60000]\n",
      "Epoch 2/20, loss: 0.092812  [19232/60000]\n",
      "Epoch 2/20, loss: 0.145425  [25632/60000]\n",
      "Epoch 2/20, loss: 0.310262  [32032/60000]\n",
      "Epoch 2/20, loss: 0.182359  [38432/60000]\n",
      "Epoch 2/20, loss: 0.215051  [44832/60000]\n",
      "Epoch 2/20, loss: 0.080634  [51232/60000]\n",
      "Epoch 2/20, loss: 0.109594  [57632/60000]\n",
      "Epoch 3/20, loss: 0.101861  [   32/60000]\n",
      "Epoch 3/20, loss: 0.319451  [ 6432/60000]\n",
      "Epoch 3/20, loss: 0.178122  [12832/60000]\n",
      "Epoch 3/20, loss: 0.069858  [19232/60000]\n",
      "Epoch 3/20, loss: 0.221224  [25632/60000]\n",
      "Epoch 3/20, loss: 0.257398  [32032/60000]\n",
      "Epoch 3/20, loss: 0.272057  [38432/60000]\n",
      "Epoch 3/20, loss: 0.191860  [44832/60000]\n",
      "Epoch 3/20, loss: 0.171167  [51232/60000]\n",
      "Epoch 3/20, loss: 0.186643  [57632/60000]\n",
      "Epoch 4/20, loss: 0.149614  [   32/60000]\n",
      "Epoch 4/20, loss: 0.076975  [ 6432/60000]\n",
      "Epoch 4/20, loss: 0.206901  [12832/60000]\n",
      "Epoch 4/20, loss: 0.079142  [19232/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 100\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 100\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     test(test_dataloader, model, loss_function)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 74\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_function, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     72\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     73\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 74\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     77\u001b[0m     loss, current \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem(), (batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(X)\n",
      "File \u001b[1;32mc:\\Users\\Lucrezia\\OneDrive - Alma Mater Studiorum Università di Bologna\\Machine Learning\\Repository\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lucrezia\\OneDrive - Alma Mater Studiorum Università di Bologna\\Machine Learning\\Repository\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\Lucrezia\\OneDrive - Alma Mater Studiorum Università di Bologna\\Machine Learning\\Repository\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    217\u001b[0m         group,\n\u001b[0;32m    218\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    223\u001b[0m         state_steps,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Lucrezia\\OneDrive - Alma Mater Studiorum Università di Bologna\\Machine Learning\\Repository\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucrezia\\OneDrive - Alma Mater Studiorum Università di Bologna\\Machine Learning\\Repository\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucrezia\\OneDrive - Alma Mater Studiorum Università di Bologna\\Machine Learning\\Repository\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:431\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    429\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 431\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Load the FashionMNIST dataset\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Use smaller batch size of 32 (the model will process 32 images at a time before updating its parameters)\n",
    "batch_size = 32\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# Define the updated MLP model\n",
    "class UpdatedMLPClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() # Converts the 2D input images into a 1D vector\n",
    "        self.linear_stack = nn.Sequential( # create a sequence of layers\n",
    "            nn.Linear(1 * 28 * 28, 1024),  # Increased neurons\n",
    "            nn.LeakyReLU(),                # Changed activation function\n",
    "            nn.Dropout(0.2),               # Added dropout (rate of 20%) to prevent overfitting\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),           # Added additional layer\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 10)             # Output layer remains the same\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits \n",
    "        # the transformation of logits into probabilities is managed by the nn.CrossEntropyLoss() function as follows\n",
    "\n",
    "# Use device (CPU or CUDA)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Instantiate the model and move to device\n",
    "model = UpdatedMLPClassifier().to(device)\n",
    "print(model)\n",
    "\n",
    "# Define loss function and optimizer (use Adam optimizer)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define the updated training function (using num_epochs parameter)\n",
    "def train(dataloader, model, loss_function, optimizer, num_epochs=20):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch, (X, y) in enumerate(dataloader): # loading a mini-batch of 32 samples (images) from the dataset\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = model(X)\n",
    "            loss = loss_function(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 200 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\") # \"current\" represents how many samples have been processed in the current batch (e.g., 256 samples).\n",
    "\n",
    "# Test function\n",
    "def test(dataloader, model, loss_function):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "# Train and test the model for 20 epochs\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_function, optimizer, num_epochs=epochs)\n",
    "    test(test_dataloader, model, loss_function)\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "sample_idx = 105\n",
    "x, y = test_data[sample_idx][0], test_data[sample_idx][1]\n",
    "\n",
    "img, label = test_data[sample_idx]\n",
    "plt.title(classes[label])\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Bag\", Actual: \"Bag\"\n",
      "------\n",
      "Probabilities (estimated):\n",
      "T-shirt/top : 0.00\n",
      "Trouser : 0.00\n",
      "Pullover : 0.00\n",
      "Dress : 0.00\n",
      "Coat : 0.00\n",
      "Sandal : 0.00\n",
      "Shirt : 0.00\n",
      "Sneaker : 0.00\n",
      "Bag : 1.00\n",
      "Ankle boot : 0.00\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    pred_probab = nn.Softmax(dim=1)(pred)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "    print('------\\nProbabilities (estimated):')\n",
    "    for i,p in enumerate(list(pred_probab[0].cpu().numpy())):\n",
    "        with np.printoptions(precision=3, suppress=True):\n",
    "            print(classes[i],\":\",format(p, \".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Changes:\n",
    "\n",
    "\n",
    "Architecture:\n",
    "Added a new fully connected layer.\n",
    "Increased the number of neurons in the hidden layers.\n",
    "Switched the activation function to LeakyReLU for improved performance.\n",
    "\n",
    "Training Procedure:\n",
    "Increased the number of epochs to 20.\n",
    "Decreased batch size to 32 for finer gradient updates.\n",
    "Changed the optimizer to Adam for adaptive learning rate adjustments.\n",
    "NB.!!!! The mprovements in performance depend on the hardware and dataset-specific characteristics. \n",
    "\n",
    "Compare the accuracy after training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (C) Exercise on MLP Linear Classification\n",
    "\n",
    "In this exercise, you are required to develop a classfier for the [QMNIST dataset](https://github.com/facebookresearch/qmnist), consisting of handwritten digits. You are entirely free to use any architecture you like. Consider using the [QMNIST torchvision dataset](https://pytorch.org/vision/main/generated/torchvision.datasets.QMNIST.html#torchvision.datasets.QMNIST).\n",
    "\n",
    "I encourage you to implement the [LeNet-5 architecture from this tutorial](https://pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html). [See here for a primer on Convolutional Neural Networks (CNNs)](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5 is a classical convolutional neural network (CNN) designed for handwritten digit classification, and it’s well-suited for this task. The network contains two convolutional layers followed by subsampling (pooling) and two fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and Preprocess the QMNIST Dataset\n",
    "\n",
    "The QMNIST dataset consists of grayscale images (1 channel) of size 28x28. We’ll normalize the pixel values for better training stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation: convert to tensor and normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with mean and std dev used for MNIST-like data\n",
    "])\n",
    "\n",
    "# Load the QMNIST dataset\n",
    "train_data = datasets.QMNIST(root=\"data\", what='train', download=True, transform=transform)\n",
    "test_data = datasets.QMNIST(root=\"data\", what='test', download=True, transform=transform)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoader for train and test datasets\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the LeNet-5 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 1 input channel (grayscale), 6 output channels (filters), 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Second convolutional layer: 6 input channels, 16 output channels\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # input from last conv layer\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)  # 10 output classes for digits 0-9\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first convolution, then pooling, then ReLU activation\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        # Apply second convolution, then pooling, then ReLU activation\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        # Flatten the tensor into a vector for fully connected layers\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        # Pass through fully connected layers with ReLU activation\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        # Output layer with no activation (for use with CrossEntropyLoss)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and move it to the device (GPU or CPU)\n",
    "model = LeNet5().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Loss Function and Optimizer\n",
    "\n",
    "For this classification task, we use the cross-entropy loss function and the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function (CrossEntropyLoss) and optimizer (Adam)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2430\n",
      "Epoch [2/10], Loss: 0.0723\n",
      "Epoch [3/10], Loss: 0.0526\n",
      "Epoch [4/10], Loss: 0.0420\n",
      "Epoch [5/10], Loss: 0.0338\n",
      "Epoch [6/10], Loss: 0.0292\n",
      "Epoch [7/10], Loss: 0.0255\n",
      "Epoch [8/10], Loss: 0.0211\n",
      "Epoch [9/10], Loss: 0.0191\n",
      "Epoch [10/10], Loss: 0.0174\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, loss_function, optimizer, num_epochs=10):\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch, (X, y) in enumerate(train_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            pred = model(X)\n",
    "            loss = loss_function(pred, y)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Train the model for 10 epochs\n",
    "train(model, train_loader, loss_function, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0497, Accuracy: 0.99 (98.67%)\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader, loss_function):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            total_loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy_percentage = accuracy * 100\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f} ({accuracy_percentage:.2f}%)\")\n",
    "\n",
    "# Test the model\n",
    "test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    cols, rows = 3, 3\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, cols * rows + 1):\n",
    "            sample_idx = torch.randint(len(test_loader.dataset), size=(1,)).item()\n",
    "            img, label = test_loader.dataset[sample_idx]\n",
    "            img = img.unsqueeze(0).to(device)  # Add batch dimension\n",
    "            \n",
    "            pred = model(img)\n",
    "            predicted_label = pred.argmax(1).item()\n",
    "\n",
    "            fig.add_subplot(rows, cols, i)\n",
    "            plt.title(f'Pred: {predicted_label}, Actual: {label}')\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(img.squeeze().cpu(), cmap=\"gray\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "* Model: LeNet-5, a classical convolutional neural network (CNN) architecture with 2 convolutional layers and 2 fully connected layers.\n",
    "* Dataset: QMNIST dataset of handwritten digits.\n",
    "* Training Setup: Adam optimizer and CrossEntropyLoss for 10 epochs with batch size 64."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
